# Speaker-Recognition
Recognition of speech is the ability to identify spoken words, and recognition of speakers is the ability to identify who is saying those words. Speaker Recognition is one of the main areas of research focused on Speech Signals. Speaking recognition, speech-to-text translation and vice-versa are other important field of study. In this paper, a brief overview of the area of speaker identification, describing its system, various modules for the extraction and modeling of features, applications, underlying techniques and some indications of performance is presented. The Mel Frequency Cepstral Coefficient (MFCC) is regarded as a key factor in the recognition of speakers. Gaussian Mixture Model (GMM) is the most popular model for data training. This considered MFCC as the primary feature with "tuned parameters," and delta- MFCC as a secondary feature and also implemented GMM with some tuned parameters to train our model. This shows that the role of identification of speakers can be performed using MFCC and GMM along with outstanding accuracy in the results of identification / diarization.

1. FEATURES EXTRACTION

Mel Frequency Cepstral Coefficent

MFCC are the Mel Frequency Cepstral Coefficients. MFCC takes into account human sensitivity experience at appropriate frequencies by converting the standard scale to Mel Scale, and is thus very suitable for speech recognition tasks (as they are suitable for human perception and the frequency at which humans speak/utter).
Feature extraction and recognition are two essential modules in speech recognition systems. The primary aim of extraction of the function is to identify robust and discriminatory features in the acoustic data. The recognition module decodes the speech input using speech features and acoustic models and generates text results with high precision. The main purpose of the extraction of feature step is to compute a saving sequence of feature vectors that provide a compact representation of the given input signal. First of all, the recording of different speech samples of each word in the vocabulary is done by different speakers. After the speech samples are collected; sampling at a frequency of 20 kHz converts them from analog to digital form. Sampling requires the recording at a regular interval of the speech signals. The data collected are now quantified if it is necessary to eliminate noise in speech samples. Speech samples collected are then passed through the extraction feature, training feature & testing stage. Feature extraction transforms the incoming sound into an internal representation so that the original signal can be reconstructed from it.

2. MODEL

Gaussian Mixture Model

Gaussian mixture models are a probabilistic model for describing subpopulations normally distributed across an overall population. Generally, mixture models do not need to know which subpopulation a data point belongs to, allowing the model to automatically learn the subpopulations. Since the role of subpopulation is not recognized, this is a form of unsupervised learning.
GMMs were used to extract features from speech data, and were also commonly used in object tracking of multiple objects, where the number of mixture components and their means predict object positions in a audio sequence at eachframe. The concept of training a GMM is to approximate the distribution of probabilities in a class by means of a linear combination of the ' k ' Gaussian distribution-clusters, also called the GMM components.
The GMM object includes the number of n components to be placed on the data, the number of iterations to n_iter in order to determine the co-variance covariance_type parameters to be accepted between the functionality and the number of times n_iter is to occur. The initialization that produced the best results is kept. The function fit) (then estimates the parameters of the model using the EM algo.
The number of iterations needed for the log-likelihood function to converge and the log-likelihood to converge.
